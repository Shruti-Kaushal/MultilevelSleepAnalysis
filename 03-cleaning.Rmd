# Data transformation

As mentioned in the introduction, for each sample or "user" many variables were sampled over the course of two days. These measurements are organized into 7 different file or categories like sleep, activity, actigraph, saliva samples etc. In this section we will focus on transforming each of the files that we used to perform any kind of analysis.

In conclusion, we worked on all the datetime columns and transformed them into the format `YYYY-MM-DD HH:MM:SS` due to analysis convenience. We decided to not include `RR.csv` in our discussion, since the heartbeat information is also included in the `actigraph.csv`. We considered it redundant and were more interested in relating heartbeat data to activities. 

```{r}
# define function
load("./data/RData/data_MMASH.RData")
library(chron)
library(dplyr)
library(tidyverse)
library(tidyr)
# create function to transform string object to time object for further calculation
string2time <- function(x, format = "%H:%M"){
  return(as.POSIXct(x, format = format)) # times(sub(".*\\s+", "",
}
```

## Sleep
The sleep file includes measurements ranging from the time the user gets into bed to the time that he gets out of bed. The measurements can be broadly grouped into two categories - one that actually relates to the quality of sleep, for example, sleep fragmentation index and the average awakening length, and other category includes time measurements, for example, the time it took for the user to fall asleep and the time he was in bed after waking up. Variables that fall in the second category have a lot of information but can be combined together to transform time measurements to duration. "Durations" can be easily compared across users in a succinct manner. However, there are some variables, like in-bed and out-bed time, that we used as is because transforming them would actually lead to a loss in information. 

There was only one user without any sleep records. Since the aim of our project is to define a metric for sleep quality and identify variables with direct or indirect effects, user 11 was excluded from all the analysis we performed. Having calculated the sleep quality for 21 users, it would be easy to treat user 11 as a missing value and apply different algorithms for imputing the value. However, this comes with a caveat - because the users are in themselves continuous categories and probably have their own distribution, looking at the entire sample space would mean that underlying distribution is multivariate. So, to effectively impute the value, we  first need to estimate the distribution parameters (even if assume that the distribution of each user is normal). This is beyond the scope of this project but we do plan to try it out if time permits.

We also discovered a pattern that every user once in bed (to sleep) doesn't get out of bed till morning except one. Sleep records of user 1 showed that he got out of bed at 3:31 AM and went back to sleep at 3:57 AM. It is hard to tell what activities did he engage in after getting out of bed briefly as the activities file (described below) does not have time stamps. For simplification of our analysis, we treated the time interval that the user was out of bed as an "awakening" i.e. when a user awaken from his sleep and remains awake for some time. This required updating the rest of the variables such as "Average Awakening Length","Sleep Fragmentation Index" etc. Depending on the definition of the variables, we either took the average or maximum or summed the two quantities corresponding to each of the "sleep sessions". For example, "Total Sleep Time" was now the sum of the sleep time in both sessions, while "Sleep Fragmentation Index" was averaged across sessions.

We will define variables wherever needed but the reader is encouraged to go through the documentation of the dataset (link in chapter 2), to understand the variables in depth. 

```{r}
# colnames(sleep)
sleep$In.Bed.Time = string2time(sleep$In.Bed.Time, format = "%H:%M") + lubridate::days(sleep$In.Bed.Date)
sleep$Out.Bed.Time = string2time(sleep$Out.Bed.Time, format = "%H:%M") + lubridate::days(sleep$Out.Bed.Date)
sleep$Onset.Time = string2time(sleep$Onset.Time, format = "%H:%M") + lubridate::days(sleep$Onset.Date)
```

## Actigraph

`Actigraph.csv` contained accelerometer and inclinometer data recorded throughout the day. Overall, it tracked users' movement data, such as steps, direction, acceleration, positions, etc. 

### Definition and explanation of each column

1. Axis1: Raw Acceleration data of the X-axis expressed in Newton-meter.
2. Axis2: Raw Acceleration data of the Y-axis expressed in Newton-meter.
3. Axis3: Raw Acceleration data of the Z-axis expressed in Newton-meter.
4. Steps: number of steps per second.
5. HR: beats per minutes (bpm).
6. Inclinometer Off: values equal to 1 refer to no activation of the inclinometer. The values are reported per second.
7. Inclinometer Standing: values equal to 1 refer to the standing position of the user, while 0 refers to other user positions. Values are reported per second.
8. Inclinometer Sitting: values equal to 1 refer to the sitting position of the user, while 0 refers to other user positions. Values are reported per second.
9. Inclinometer Lying: values equal to 1 refer to the lying position of the user, while 0 refers to other user positions. Values are reported per second.
10. Vector Magnitude: vector movement derived from raw acceleration data expressed in Newton-meter.
11. day: 1 and 2 refer to the first and second day of data recording, respectively.
12. time: day time when the heartbeat happened (hours:minutes:seconds)

### Transformation process:

1. Datetime format: We transform the `time` column into datetime type in R. Also, since initial `time` column doesn't contain date information, we add days according to the `day` column to create a relative time stamp for each record in order to facilitate future calculation.

2. Create category `Position`: Here we gathered columns with inclinometer information, which were `Inclinometer.Off`, `Inclinometer.Standing`, `Inclinometer.Sitting`, `Inclinometer.Lying`, transformed them into categorical column `Position`. By doing so, we can explore data correlations under groups of position throughout the day.



```{r}
library(lubridate)
library(dplyr)
actigraph[actigraph$day == -29,]$day = 2
actigraph$time = string2time(actigraph$time, format = "%H:%M:%S") + lubridate::days(actigraph$day)
# actigraph$duration = lead(actigraph$time) - actigraph$time
# actigraph$duration.secs = as.numeric(actigraph$duration)
# Verify at least one value of Inclinometer is true: True
# all((actigraph[7] == 1) | (actigraph[8]== 1) | (actigraph[9]== 1) | (actigraph[10]== 1))

position = cbind(actigraph[1],actigraph[14], actigraph[7:10]) %>%
  group_by(X, user) %>%
  gather(position, val, -c(X,user)) %>%
  filter(val == 1) %>%
  select(-val) %>%
  arrange(user, X)

actigraph$position = position$position


position = actigraph %>% 
  group_by(user) %>% 
  mutate(duration = (lead(time) - time)) %>%
  ungroup() %>% 
  group_by(user, position) %>% 
  summarise(total = sum(duration, na.rm = TRUE), .groups = "keep")


```

## Activity

### Definition and explanation of each column
'Start' and 'end' columns refer to the time of the day (hours:minutes) when the event happened, while 'day' columns refers to the day when it happened (1 and 2 refer to the first and second day of data recording, respectively).

### Transformation process:

1. Datetime format: Here we substitute "00:00" to "24:00" in column `End` to avoid calculating between wrong dates, and then transformed into the format as we did for `Actigraph.csv`.

2. Relabel the activities: The document labeled the activity categories from 1 to 12. However, an extra category, labeled as `0`, also included in the dataset. In this project, we will assume that the `0` represented undetermined activities. Here, we also had to deal with several minor mistakes in the dataset manually.

+ 13 Categories of activity:
  - undefined: all other unlabeled activity will count here.
  - sleeping
  - laying down
  - sitting: e.g. studying and driving
  - light mvmnt: e.g. slow/medium walk, chores and work.
  - medium: e.g. fast walk and bike
  - heavy: e.g. gym, running.
  - eating
  - small scr.usg: e.g. smartphone and computer.
  - large scr.usg: e.g. TV and cinema.
  - caff. consump.: caffeinated drink consumption, e.g. coffee or coke.
  - smoking
  - alc. consump.: alcohol assumption.

3. Calculate duration for each activity: To figure the total time each user spent on each activity, we calculate time intervals (`End` - `Start`) between different activities in seconds.

4. Plotting: We explored the dataset using `geom_tile` in ggplot2 package. From the plot below, we noticed that user 21 was laying down for quite a long time.


```{r, fig.width=10}
library(ggplot2)
activity$Start = string2time(activity$Start)+ lubridate::days(activity$Day)
# we need to substitute "00:00" to "24:00" to prevent calculating on the wrong day
activity$End = sub("00:00", "24:00", activity$End)
activity$End = string2time(activity$End)+ lubridate::days(activity$Day)

# wrong inputs for activity start time and end time
# switch start time and end time
# activity[activity$End < activity$Start & !is.na(activity$End),] 
temp = activity[c(413,428,445),]$Start
activity[c(413,428,445),]$Start = activity[c(413,428,445),]$End
activity[c(413,428,445),]$End = temp

# some has records across time
activity$End[activity$End < activity$Start & !is.na(activity$End)] = activity$End[activity$End < activity$Start & !is.na(activity$End)] + lubridate::days(1)
 
# duration in seconds
activity_duration = activity %>% 
  group_by(user) %>% 
  mutate(duration = End - Start) %>%
  ungroup() %>% 
  group_by(user, Activity) %>% 
  summarise(total = as.numeric(sum(duration, na.rm = TRUE)), .groups = "keep")

# label of activity ID
ID_activity <- data.frame(ID = 0:12, category = c(
  "undefined",
  "sleeping",
  "laying down",
  "sitting",
  "light mvmnt",
  "medium",
  "heavy",
  "eating",
  "small scr.usg", 
  "large scr.usg", 
  "caff. consump.",
  "smoking",
  "alc. consump." 
))

activity_duration = activity_duration %>% left_join(ID_activity, by = c('Activity' = "ID"))


activity_duration %>% ggplot(aes(x = factor(user, levels = paste0("user_",c(1:22)), labels = c(1:22)), y = factor(category), alpha = total)) +
  geom_tile(color = 'black', lwd = 0.4, linetype = 1) +
  scale_x_discrete(labels = abbreviate) +
  theme(panel.background = element_blank() ) + 
  xlab("User ID") + 
  ylab("Activity") +
  ggtitle("Time spent on each activity")
```



<!-- ## Questionnaire -->

<!-- For this part, the dataset contains the answer of a total of 7 questionnaires for each user. The questionnaires examined users' anxiety, sleep quality, stress, emotion, etc, in order to understand the users' behavior. -->

<!-- No data cleaning is needed for this part. -->

<!-- ### Definition and explanation of each column -->

<!-- questionnaire.csv - scores for all the questionnaires: -->

<!-- *TODO: make visualization for each scale and score of each questionnaire.csv.* -->

<!-- 1. MEQ: Morningness-Eveningness Questionnaire value. The chronotype score is ranging from 16 to 86: scores of 41 and below indicate Evening types, scores of 59 and above indicate Morning types, scores between 42-58 indicate intermediate types. -->

<!-- 2. STAI1: State Anxiety value obtained from State-Trait Anxiety Inventory. The results are range from 20 to 80. Scores less than 31 may indicate low or no anxiety, scores between 31 and 49 an average level of anxiety or borderline levels, and scores higher than 50 a high level of anxiety or positive test results. -->

<!-- 3. STAI2: Trait Anxiety value obtained from the State-Trait Anxiety Inventory. The results are range from 20 to 80. Scores less than 31 may indicate low or no anxiety, scores between 31 and 49 an average level of anxiety or borderline levels, and scores higher than 50 a high level of anxiety or positive test results. -->

<!-- 4. PSQI: Pittsburgh Sleep Quality Questionnaire Index. It gives a score rating from 0 to 21, with values lower than 6 indicating good sleep quality. -->

<!-- 5. BIS/BAS: Behavioural avoidance/inhibition index. BIS/BAS scales are a typical measure of reinforcement sensitivity theory that establish biological roots in personality characteristics, derived from neuropsychological differences. The BIS/BAS scales comprise a self‐report measure of avoidance and approach tendencies that contains four sub-factors (A high score in one of the subscale describes the degree of that temperamental characteristic for the individual, according to the original sample): -->

<!--   + Bis facet: reflects subject sensitivity toward aversive events that promote avoidance behaviours. -->
<!--   + Drive: describes individual persistence and motivational intensity. -->
<!--   + Reward: corresponds to Reward Responsiveness that indicates a propensity to show a higher degree of positive emotion for goal attainment. -->
<!--   + Fun: corresponds to Fun-Seeking that is related to impulsivity and immediate reward due to sensory stimuli or risky situations. -->

<!-- 6. Daily_stress: Daily Stress Inventory value (DSI) is a 58 items self-reported measures which allows a person to indicate the events they experienced in the last 24 hours. After indicating which event occurred, they indicate the stressfulness of the invent on a Likert scale from 1 (occurred but was not stressful) to 7 (Cause me to panic). It gives a score between 0 and 406. The higher is this values, the higher is the frequency and degree of the events and the perceived daily stress. -->

<!-- 7. PANAS: Positive and Negative Affect Schedule. It gives a score rating between 5 and 50 for both positive and negative emotions. The higher is the PANAS value, the higher is the perceived emotion. Columns name with 10, 14, 22 and 9+1 refer to the time of the day when the questionnaire is filled in. 9+1 indicates the 9 AM of the second recording day. -->


<!-- ## RR -->

<!-- `RR` dataset contains the heartbeat records for each user. We can transform `ibi_s` to rate of heartbeat and align with activity records using `time` column. -->

<!-- Similar to `Actigraph` dataset, the only thing we need to do here is to transform the `time` column into datetime type in R. Also, since initial `time` column doesn't contain date information, we add days according to the `day` column to create a relative time stamp for each record in order to facilitate future calculation. -->

<!-- ### Definition and explanation of each column -->

<!-- RR.csv - beat-to-beat interval data: -->

<!-- 1. ibi_s: time in seconds between two consecutive beats. -->
<!-- 2. day: 1 and 2 refer to the first and second day of data recording, respectively. -->
<!-- 3. time: day time when the heartbeat happened (hours:minutes:seconds) -->

<!-- ```{r} -->
<!-- RR$time = string2time(RR$time, format = "%H:%M:%S") + lubridate::days(RR$day) -->
<!-- ``` -->


## Saliva
`Saliva.csv` collected `Melatonin` and `Cortisol` concentrations in the saliva for each participants before going to bed and after waking up. However, no data was provided for User_21 due to problem in the salivary samples that do not permit to analyse it.

### Definition and explanation of each column

1. Sample: Two samples per participant are included, one before sleep and one after waking up.
2. Melatonin levels are reported in μg of melatonin per μg of protein.
3. Cortisol levels are in μg of cortisol per 100 μg of protein. 

### Transformation process
We calculated the difference in chemical concentration between sample collected before sleep and after waking up per each participant. 


## User info

missing age for user_18. Otherwise, nothing need to be transformed or cleaned in this dataset. All male participants.

### Definition and explanation of each column

user_info.csv - anthropocentric characteristics of the participant:

1. gender: M and F refer to Male and Female, respectively.
2. height is expressed in centimetre (cm).
3. weight is expressed in kilograms (kg).
4. age is expressed in years.

```{r}
# BMI
```


```{r}
# save workplace after data cleaning/for this stage.
save.image(file = "./data/RData/data_MMASH_cleaned.RData")
```